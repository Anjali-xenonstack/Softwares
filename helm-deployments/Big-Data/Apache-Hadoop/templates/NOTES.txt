<pre>

Big Data Stack Deployment Details :::

You have successfully launched following components under this  :

• Apache Hadoop ( HDFS NameNode & DataNode + YARN NodeManager & ResourceManager)
• Apache HBase Master , ThriftServer & RegionServer
• Apache Hive
• Cloudera Hue
• Apache ZooKeeper
• Apache Oozie
• Apache Pig
• Apache Sqoop
• Apache Flume


Visit on following URL addresses to use various big data services (It might take a couple of seconds for all services to attain Running state .. Please wait) :

• Hadoop HDFS NameNode : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.webhdfs}}">http://{{.IP}}:{{.webhdfs}}</a>

• Hadoop HDFS DataNode : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.dnhdfs}}">http://{{.IP}}:{{.dnhdfs}}</a>

• Hadoop YARN ResourceManager : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.yarnweb}}">http://{{.IP}}:{{.yarnweb}}</a>

• Hadoop YARN NodeManager : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.yarnnm}}">http://{{.IP}}:{{.yarnnm}}</a>

• HBASE Master Dashboard : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.hbasemasterui}}">http://{{.IP}}:{{.hbasemasterui}}</a>

• HBASE ThriftServer UI : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.thriftinfo}}">http://{{.IP}}:{{.thriftinfo}}</a>

• HBASE RegionServer UI : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.hbaseregionui}}">http://{{.IP}}:{{.hbaseregionui}}</a>

• You can connect to Hive server in 3 ways :

1) By Going into the pod - Copy the below line & Enter into the pod using Console in Dashboard & Run :

   beeline -u jdbc:hive2://localhost:10000/default

2) If you already have a beeline client & you want to connect remotely, Run from your terminal :

   beeline -u jdbc:hive2:// {{.IP}}:{{.hiveserver}}/default

3) Using Hive Shell from Hue Dashboard - Login to Hue & you can run commands remotely to the Hive server from Hue dashboard


• Oozie WebUI : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.httpoozie}}">http://{{.IP}}:{{.httpoozie}}</a>


• To run Sqoop , Go into Console of Sqoop & Run

  sqoop2-shell

  It will open a shell & you can run commands from inside the shell

OR To access Sqoop from your program (Scala,Java or any other language) or from any other tool :
Enter following to connect to Sqoop : http://{{.IP}}:{{.datasqoop}}


• To check connectivity to Flume : Run following command from any terminal from anywhere :

curl -X POST \
    -H 'Content-Type: application/json; charset=UTF-8' \
    -d '[{"headers":{"header.key":"header.value"}, "body":"hello world"}]' http://{{.IP}}:{{.flumehttp}}

If it prints Ok a couple of times , means Flume is configured properly ✔

Further , to use it , Your can Go into console from Dashboard


• To run Pig , Go into Console of Sqoop & Run

  pig

  It will connect to Hadoop HDFS(which has persistent storage attached) & open a Grunt shell

• Access Hue UI at : <a style="text-decoration:none;" target="blank" href="http://{{.IP}}:{{.httphue}}">http://{{.IP}}:{{.httphue}}</a>

  Provide UserName : root
          Password : root
</pre>
