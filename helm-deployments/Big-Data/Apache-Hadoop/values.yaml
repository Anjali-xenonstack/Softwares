hbaseregion:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/spark:hbaseregionv2.2 #bde2020/hbase-regionserver:1.0.0-hbase1.2.6
  replicas: 1
  resources:
    requests:
      memory: "400Mi"
      cpu: "300m"
    limits:
      memory: "400Mi"
      cpu: "300m"

hue:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/apachehue:v37 #32 #29 #1 #6 #1 #5 #1 1 #3 #2 #1

hive:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/spark:hivev2.2
  imagepsql: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/spark:hivepsqlv2.3 #2.2

zookeeper:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/spark:zoov2.2 #zookeeper

source:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/flume:sourcev2.2 # 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/flume:source # dr.xenon.work/testing/flume:source

sink:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/flume:sinkv2.2 # 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/flume:sink # dr.xenon.work/testing/flume:sink

oozie:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/jupyternotebook:ooziev6

sqoop:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/flume:sqoopv2.2

pig:
  image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/flume:pigv2.2 # 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/flume:pig

# The base hadoop image to use for all components.
# See this repo for image build details: https://github.com/Comcast/kube-yarn/tree/master/image
image: 801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/spark:hadoopv2.2 #danisla/hadoop:2.7.3
imagePullPolicy: IfNotPresent

# The version of the hadoop libraries being used in the image.
hadoopVersion: 2.7.3

# Select anitAffinity as either hard or soft, default is hard
antiAffinity: "soft"

hdfs:
  nameNode:
    pdbMinAvailable: 1

    resources:
      requests:
        memory: "500Mi"
        cpu: "300m"
      limits:
        memory: "500Mi"
        cpu: "300m"

  dataNode:
    replicas: 2

    pdbMinAvailable: 1

    resources:
      requests:
        memory: "400Mi"
        cpu: "200m"
      limits:
        memory: "400Mi"
        cpu: "200m"

yarn:
  resourceManager:
    pdbMinAvailable: 1

    # resources:
    #   requests:
    #     memory: "500Mi"
    #     cpu: "300m"
    #   limits:
    #     memory: "500Mi"
    #     cpu: "300m"

  nodeManager:
    pdbMinAvailable: 1

    # The number of YARN NodeManager instances.
    replicas: 2 #2

    # Create statefulsets in parallel (K8S 1.7+)
    parallelCreate: false

    # CPU and memory resources allocated to each node manager pod.
    # This should be tuned to fit your workload.
    # resources:
    #   requests:
    #     memory: "400Mi" #"2048Mi"
    #     cpu: "200m" #"1000m"
    #   limits:
    #     memory: "400Mi" #"2048Mi"
    #     cpu: "200m" #"1000m"

persistence:
  nameNode:
    enabled: true
    storageClass: gp2
    accessMode: ReadWriteOnce
    size: 5Gi

  dataNode:
    enabled: true
    storageClass: gp2
    accessMode: ReadWriteOnce
    size: 8Gi

# imagedb: "801204773696.dkr.ecr.ap-southeast-1.amazonaws.com/sl/spark"
# imageTagdb: "mysqlv3.1" #2.8 #2.2  # "v2.7"   "5.7.14"

## Specify password for root user
##
## Default: random 10 character string
# mysqlRootPassword: root

## Create a database user
##
# mysqlUser:
# mysqlPassword:

## Allow unauthenticated access, uncomment to enable
##
# mysqlAllowEmptyPassword: true

## Create a database
##
# mysqlDatabase: hue

livenessProbe:
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 3

readinessProbe:
  initialDelaySeconds: 5
  periodSeconds: 10
  timeoutSeconds: 1
  successThreshold: 1
  failureThreshold: 3



## Persist data to a persistent volume
persistencedb:
  enabled: true
  ## database data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: default
  accessMode: ReadWriteOnce
  size: 5Gi
  sizezoo: 1Gi

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 256Mi
    cpu: 100m
