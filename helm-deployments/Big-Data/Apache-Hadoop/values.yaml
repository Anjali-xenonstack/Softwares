hbaseregion:
  image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/spark:hbaseregionv2.2 #bde2020/hbase-regionserver:1.0.0-hbase1.2.6
  replicas: 1
  resources:
    requests:
      memory: "256Mi"
      cpu: "10m"
    limits:
      memory: "2048Mi"
      cpu: "1000m"

hive:
  image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/spark:hivev2.2
  imagepsql: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/spark:hivepsqlv2.2

zookeeper:
  image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/spark:zoov2.2 #zookeeper

source:
  image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/flume:sourcev2.2 # 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/flume:source # dr.xenon.work/testing/flume:source

sink:
  image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/flume:sinkv2.2 # 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/flume:sink # dr.xenon.work/testing/flume:sink

flume:
  resources:
    limits:
      memory: "4096Mi"
      cpu: "2000m"

oozie:
  image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/jupyternotebook:ooziev6

sqoop:
  image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/flume:sqoopv2.2
  resources:
    limits:
      memory: "4096Mi"
      cpu: "2000m"

pig:
  image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/flume:pigv2.2 # 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/flume:pig

# The base hadoop image to use for all components.
# See this repo for image build details: https://github.com/Comcast/kube-yarn/tree/master/image
image: 190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/spark:hadoopv2.2 #danisla/hadoop:2.7.3
imagePullPolicy: IfNotPresent

# The version of the hadoop libraries being used in the image.
hadoopVersion: 2.7.3

# Select anitAffinity as either hard or soft, default is hard
antiAffinity: "soft"

hdfs:
  nameNode:
    pdbMinAvailable: 1

    resources:
      requests:
        memory: "256Mi"
        cpu: "10m"
      limits:
        memory: "2048Mi"
        cpu: "1000m"

  dataNode:
    replicas: 1

    pdbMinAvailable: 1

    resources:
      requests:
        memory: "256Mi"
        cpu: "10m"
      limits:
        memory: "2048Mi"
        cpu: "1000m"

yarn:
  resourceManager:
    pdbMinAvailable: 1

    resources:
      requests:
        memory: "256Mi"
        cpu: "10m"
      limits:
        memory: "2048Mi"
        cpu: "2000m"

  nodeManager:
    pdbMinAvailable: 1

    # The number of YARN NodeManager instances.
    replicas: 2

    # Create statefulsets in parallel (K8S 1.7+)
    parallelCreate: false

    # CPU and memory resources allocated to each node manager pod.
    # This should be tuned to fit your workload.
    resources:
      requests:
        memory: "2048Mi"
        cpu: "1000m"
      limits:
        memory: "2048Mi"
        cpu: "1000m"

persistence:
  nameNode:
    enabled: true
    storageClass: gp2
    accessMode: ReadWriteOnce
    size: 5Gi

  dataNode:
    enabled: true
    storageClass: gp2
    accessMode: ReadWriteOnce
    size: 8Gi

imagedb: "190742198407.dkr.ecr.us-west-2.amazonaws.com/xl/spark"
imageTagdb: "mysqlv2.2" #"5.7.14"

## Specify password for root user
##
## Default: random 10 character string
mysqlRootPassword: root

## Create a database user
##
# mysqlUser:
# mysqlPassword:

## Allow unauthenticated access, uncomment to enable
##
# mysqlAllowEmptyPassword: true

## Create a database
##
mysqlDatabase: hue

## Specify an imagePullPolicy (Required)
## It's recommended to change this to 'Always' if the image tag is 'latest'
## ref: http://kubernetes.io/docs/user-guide/images/#updating-images
##

livenessProbe:
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  successThreshold: 1
  failureThreshold: 3

readinessProbe:
  initialDelaySeconds: 5
  periodSeconds: 10
  timeoutSeconds: 1
  successThreshold: 1
  failureThreshold: 3



## Persist data to a persistent volume
persistencedb:
  enabled: true
  ## database data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: default
  accessMode: ReadWriteOnce
  size: 5Gi
  sizezoo: 1Gi

## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
  requests:
    memory: 256Mi
    cpu: 100m

# Custom mysql configuration files used to override default mysql settings
configurationFiles:
#  mysql.cnf: |-
#    [mysqld]
#    skip-name-resolve


## Configure the service
## ref: http://kubernetes.io/docs/user-guide/services/
service:
  ## Specify a service type
  ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services---service-types
  type: NodePort
  port: 3306
